%% start of file `template.tex'.
%% Copyright 2006-2010 Xavier Danaux (xdanaux@gmail.com).
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License version 1.3c,
% available at http://www.latex-project.org/lppl/.

% A modern LaTeX CV template config links:
% https://www.baeldung.com/cs/latex-moderncv-resume

%------------- PACKAGES --------------------------------------------

\documentclass[11pt,a4paper,english, sans]{moderncv}      % a4paper, a5paper, b5paper, letterpaper, legalpaper, executivepaper, landscape
                                                    % 10pt, 11pt, 12pt
% moderncv themes
%\moderncvtheme[green]{casual}              % optional argument are 'blue' (default), 'orange', 'red', 'green', 'grey' and 'roman' (for roman fonts, instead of sans serif fonts)
                                            % casual (default), classic, banking, oldstyle, fancy
\moderncvtheme[green]{classic}

% adjust the page margins
\usepackage[scale=0.8]{geometry}
% \usepackage[scale=0.75]{geometry}

% Font encoding and family
% \usepackage[utf8]{inputenc}                   % character encoding: replace by the encoding you are using
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% language
\usepackage[english]{babel}

% symbols
\usepackage{amssymb}

% additional packages for safety
%\usepackage{hyperref}
\usepackage{enumitem}

%------------- PACKAGES --------------------------------------------


%------------- PERSONAL DATA --------------------------------------------
% personal data
\firstname{\Huge Francisco}
\familyname{\Huge Perez-Sorrosal}
\title{Princ. Research Engineer (Yahoo Inc.)}            % optional, remove the line if not wanted
\address{N/A}{94123 San Francisco, CA (U.S.)}            % optional, remove the line if not wanted
% \address{N/A}{N/A}
\mobile{Ask through LinkedIn}                            % optional, remove the line if not wanted
\email{Ask through LinkedIn}                             % optional, remove the line if not wanted
\social[linkedin]{fperezsorrosal}
\homepage{http://francisco-perez-sorrosal.github.io/}    % optional, remove the line if not wanted
%\extrainfo{\homepagesymbol~\href{http://xxxx}{xxx}}      % optional, remove the line if not wanted
%\phone{phone (optional)}                                % optional, remove the line if not wanted
%\fax{fax (optional)}                                    % optional, remove the line if not wanted
%\homepage{ch.linkedin.com/in/juanperezsorrosal}         % optional, remove the line if not wanted
%\photo[44pt]{fotoFranGuayV2.jpg}                        % '64pt' is the height the picture must be resized to and 'picture' is the name of the picture file; optional, remove the line if not wanted
%------------- PERSONAL DATA --------------------------------------------

%------------- QUOTE --------------------------------------------
% Quote (optional)
%\quote{“Success is not final, failure is not fatal: It is the courage to continue that counts.” - Winston Churchill}
%\quote{“Integrity is doing the right thing, even when no one is watching.” — C. S. Lewis}
%\quote{“Strive not to be a success, but rather to be of value.” — Albert Einstein}
%\quote{Computers are useless. They can only give you answers. - Pablo Picasso}
\quote{\textit{"Any man could, if he were so inclined, be the sculptor of his own brain." -- Santiago Ram\'on y Cajal}}
%------------- QUOTE --------------------------------------------


%\nopagenumbers{}                             % uncomment to suppress automatic page numbering for CVs longer than one page
%------------- CONTENT SETUP --------------------------------------------

% Page numbering (yes/no)
%\nopagenumbers{}

%\setlength{\hintscolumnwidth}{3cm}						% if you want to change the width of the column with the dates
%\AtBeginDocument{\setlength{\maketitlenamewidth}{8.3cm}}  % only for the classic theme, if you want to change the width of your name placeholder (to leave more space for your address details
\AtBeginDocument{\recomputelengths}                     % required when changes are made to page layout lengths

% Compact itemize globally with smaller bullets
\setlist[itemize]{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt,label={\tiny$\bullet$}}

%------------- BIBLIOGRAPHY --------------------------------------------
% to show numerical labels in the bibliography; only useful if you make citations in your resume
\makeatletter
\renewcommand*{\bibliographyitemlabel}{\@biblabel{\arabic{enumiv}}}
\makeatother

% bibliography with mutiple entries
%\usepackage{multibib}

%\newcites{book,misc}{{Books},{Others}}

%------------- BIBLIOGRAPHY --------------------------------------------

%------------- BEGIN DOCUMENT --------------------------------------------

\begin{document}

\maketitle
\vspace{0.1cm}

%------------- PROFILE AND GOALS --------------------------------------------
\section{Profile and Goals}

\small I am a reliable, goal-oriented, and detail-focused professional with extensive experience in research and software engineering across both academic and industry settings, specializing in machine learning, artificial intelligence, and distributed systems. As a Research Engineer, I am curious and love exploring and implementing with cutting-edge technologies, particularly in AI/ML, to tackle complex challenges and foster innovation. As a Software Engineer, I can design, develop, and ensure the maintainability of robust and scalable big data applications, whether on-prem or cloud, always prioritizing high availability, scalability, performance, and reliability. I am adaptable, capable of taking initiative and leading efforts with a strategic approach when needed, or collaborating as a communicative, supportive, and empathetic team player to achieve shared goals. I thrive in open, dynamic, and multidisciplinary environments, integrating visionary and practical insights to deliver impactful results while empowering others and fostering collaboration.
%------------- PROFILE AND GOALS --------------------------------------------
\vspace{0.2cm}
%------------- PROFESSIONAL EXPERIENCE --------------------------------------------
\section{Professional Experience}

% When possible follow this \cventry syntax: \cventry{{period/year(s)}}{{job position}}{{company}}{{role(s)}}{{location (optional)}}{{description using LaTeXitemized lists}}

\cventry{2025--Now}{\large Independent AI Research \& Strategic Advisor}{\textcolor{black}{Focus: Agentic AI \& LLM Apps}}{}{}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item \textbf{Agentic AI}: Deep-dive research of multi-agent systems, \textit{LLM orchestration}, and autonomous reasoning frameworks; evaluated cutting-edge frameworks including \textit{AutoGen}, \textit{CrewAI}, \textit{OpenAI} and custom agentic workflows.
\item \textbf{Strategic Advisory}: Provided technical guidance to early-stage startups (\textit{Eni6ma}, \href{https://wasmer.io/}{\textit{Wasmer}}) on AI strategy, model selection, and production requirements; advised on \textit{Agentic AI} integration patterns and AI architecture design.
\item \textbf{Continuous Learning}: maintained cutting-edge expertise in rapidly evolving field.
\end{itemize}
}

\cventry{2023--2024}{\large Principal Research Engineer}{Knowledge Graph Science @ Yahoo Inc.}{\textbf{Roles}: ML/AI Expert, MLOps}{Sunnyvale}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item \textbf{Dataset Quality Improvement (2024)}: \textbf{Goal} -- Since the labels of most entity pairs were generated in a semi-supervised manner, develop an LLM-based solution to validate and enhance the labeling accuracy of the dev and test datasets. \textbf{Achievement} -- Implemented a generative Entity Matching solution with Llama 2 to identify and fix (by re-labeling) misclassified examples in the dev/test sets.
\item \textbf{Entity Reconciliation Model Training (2023-2024)}: Fine-tuned transformer-based language models on heterogeneously labeled datasets, integrating editorially curated data with automatically labeled data through entity linking via common identifiers. This approach aimed to deduplicate and reconcile meta-entities related to People and Creative Works. \textbf{Goal} -- Improve current production metrics on both categories. \textbf{Achievements} -- (1) Trained and optimized a unified, type-agnostic LM model for entity matching/reconciliation, replacing tens of type-specific production models and simplifying the maintenance of the reconciliation stage in the Knowledge Graph; (2) Metric improvements: overall increases of 22.23\% and 16.11\% in precision and recall for Person, and 5\% and 4\% for Creative Works; (3) Reduced model size by 33\%, lowering storage requirements and improving efficiency without compromising accuracy.
\item \textbf{Entity Reconciliation Pipeline (2023)}: Built pipelines for distributed sampling, preprocessing, and transformation of large-scale entity data extracted from various complementary sources that accurately reflect user search behavior. Developed an automated pipeline for training entity reconciliation models for YK, from data curation to inference testing. \textbf{Achievements} -- (1) Devised a solution to reduce the number of models maintained in production from $\sim$30 heterogeneous (heuristic-based, SVMs, Tree-based) to just 4, which encompass the main 4 meta-entity types in YK; (2) Expanded entity type coverage to 20 new types of people entities (e.g., directors, producers, composers, writers, politicians) and 32 new types of creative works (e.g., visual works, theatrical works, critic's reviews, periodicals, poems).
\item \textbf{Entity Reconciliation Inference (2023)}: \textbf{Goal} -- Design and architect a PoC solution for cloud-based inference. \textbf{Achievement} -- Implemented a Ray Serve-based solution to deploy new YK models in the cloud, optimizing for cost efficiency by evaluating CPU and GPU-based approaches.
\end{itemize}
}

\cventry{Jun--Dec 2022}{\large Principal Research Engineer}{Mail @ Yahoo}{\textbf{Roles}: ML/AI Expert}{Sunnyvale}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item \textbf{Kamino Project - Mail Classification System}: \textbf{Goal} -- Upgrade legacy production models to a new generation of deep learning-based, small distilled models optimized for large-scale deployment. These models were designed to classify incoming mail using a newly developed multilabel taxonomy tailored to the mail team's specific use cases. \textbf{Approach} -- Developed a deep learning pipeline using Hugging Face to train/evaluate models based on the Teacher/Student knowledge distillation framework. Starting with limited human-labeled training data, a large and complex teacher model was created to achieve high accuracy. This model was then used to generate teacher-labeled data for training lightweight student models optimized for deployment. Two types of student models were produced: (1) online models, optimized for speed and suitable for real-time classification tasks, and (2) offline models, designed to include richer information for improved accuracy in non-real-time applications. \textbf{Achievements} -- The resulting student models for an expanded taxonomy, more than doubling the number of deployable categories in the taxonomy while improving performance on existing categories in production by 3.1-5.9\%.
\end{itemize}
}

\cventry{Apr--Dec 2022}{\large Technical Advisor}{Digital Transformation Office @ Yahoo}{\textbf{Roles}: ML/AI Expert, Strategy}{Sunnyvale}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item \textbf{AI/ML Working Group - AI/ML Future Strategy Definition in the Cloud}: As Yahoo transitioned its infrastructure from on-premises data centers to a fully cloud-based environment, scientists and research engineers required modern tools to streamline their workflows. These tools needed to facilitate dataset and model sharing, ensure reproducibility of experiments, enable rapid experimentation and iteration on new models, and support seamless publishing and deployment into pre-production/production environments. \textbf{Goal} -- Specifically, the Model Development subgroup was dedicated to establishing the requirements, standards, tools, and frameworks needed to scale ML/DL applications effectively across the company. \textbf{Achievements} -- (1) Led the discussions on the Model Development subgroup, although participated actively in the remaining three (Data Management, Model Management, and Model Serving); (2) Delivered a set of recommendations (prioritized and categorized in topics) and tasks to do (internal processes, external relations, tools, etc.) to guarantee that ML/DL practitioners could work with less friction in the new cloud environments.
\end{itemize}
}

\cventry{2021--2022}{\large Principal Research Engineer}{Ads @ Yahoo}{\textbf{Roles}: ML/AI Expert, Strategy}{Sunnyvale}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item \textbf{Contextual Targeting Solution}: In the Ads platform, as we were moving towards a cookie-less world, the ability to track users' online signals for behavioral targeting would be drastically reduced, making contextual targeting an appealing alternative for advertising platforms. Using our experience in hierarchical multilabel classification in other contexts, we helped the Ads team to use it in category-based contextual targeting at Yahoo. We proposed and implemented a multilingual model that can accurately classify web pages into a hierarchical taxonomy (specifically, the Yahoo Interest Categories taxonomy) without crawling their content. \textbf{Goal} -- Transfer the knowledge and experience in taxonomy-based multi-label classification to the Ads team and build a platform for training/evaluating the models. \textbf{Achievements} -- (1) Helped the Ads team to develop a pipeline for training models for the task at hand; (2) \textit{Multilingual taxonomic web page classification for contextual targeting at Yahoo} paper (ACM SIGKDD 2022) \textbf{7 Citations}.
\end{itemize}
}

\cventry{2018--2022}{\large Principal Research Engineer}{Science @ Content Platform @ Verizon Media/Oath}{\textbf{Roles}: ML/DL Engineer, Research Engineer}{Sunnyvale}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item \textbf{Deep Learning-based Multi-label Classification (2020-2021)}: \textbf{Goal} -- Modernize the production models and infrastructure using new deep learning models. \textbf{Achievements} -- (1) Developed a modern pipeline based on HuggingFace Transformers to train/evaluate multi-label, multi-class and binary classification problems; (2) Built a tool for plugin taxonomies for the multi-label configurations; (3) Trained new models obtaining significantly better metrics over the ones in production (+10\% over baseline); (4) Developed a serving pipeline based on NVIDIA's Triton Server to deploy in production.
\item \textbf{Scalable Few-shot Classification with Parallel Prefix Conditioning (2021)}: \textbf{Goal} -- Modify a transformer architecture (e.g. BERT) to achieve fast and effective few-shot classification by prefixing multiple category labels to the input. \textbf{Method} -- Class representations are encoded in parallel but produce independent binary labels for each input through a shared classification output layer. \textbf{Achievements} -- (1) Conducted experiments on the DBPedia dataset demonstrating improved few-shot performance over standard multi-class classifiers and a speedup over binarized formulations; (2) Further analysis showed that the approach could be scaled to a large number of categories and may hold promise for zero-shot learning of unseen categories.
\item \textbf{Clickbait Classifier based on Transformers (2019)}: \textbf{Goal} -- Improve the current SVM-based model in production using a BERT-based model. \textbf{Achievements} -- (1) Proposed an integration strategy for serving the model in production using the existing pipeline; (2) The F1 metric was improved over 5\% over current classifier in production; (3) PoC of a generative-based clickbait classification approach using Google's T5.
\item \textbf{Hierarchical Transfer Learning for Multi-label Text Classification (2018)}: \textbf{Goal} -- Propose a novel transfer learning based strategy where binary classifiers at lower levels in a hierarchy of classes are initialized using parameters of the parent classifier and subsequently fine-tuned on the child categories for the classification task. \textbf{Achievement} -- Paper published in ACL 2019: \textit{Hierarchical transfer learning for multi-label text classification}. In ACL, 2019 \textbf{127 Citations}.
\end{itemize}
}

\cventry{2015--2018}{\large Senior Research Engineer}{Content Ingestion Platform (CAP) @ Yahoo Inc.}{\textbf{Roles}: ML/DL Engineer}{Sunnyvale}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item \textbf{DL-based Multi-class Classification for Content Ingestion (2018)}: Experimented with LSTM/GRU-based models for multi-class classification using TF/Keras. Explored transfer learning techniques for multi-label text classification.
\item \textbf{Machine Learning Content Classification Pipeline (2017)}: Built a pipeline for easy data ingestion, model training and evaluation based on SVMs for the Sieve platform.
\item \textbf{ML Pipeline Scalability (2017)}: Built k8s-make, a tool and a workflow-based framework to harness the compute-power in Yahoo's on-prem clusters to deploy a tailor-made Kubernetes cluster to parallelize the training of our SVM-based pipeline in a simple way.
\end{itemize}
}

\cventry{2015--2017}{\large Senior Research Engineer}{Sieve @ Yahoo Inc.}{\textbf{Roles}: Distributed Systems Expert, Research Engineer}{Sunnyvale}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item \textbf{Twitter Firehose: At-scale Ingestion Streaming System for Tweets (2017)}: Reimplemented the new Twitter API (v2.0) in the firehose. Re-architected previous solution to be more performant yet keeping backwards compatibility. Collaborated with the Sports team for the productization of the new firehose.
\item \textbf{Scalable Content Ingestion Platform (2016)}: Transferred Omid as full open-source project into the \href{https://github.com/apache/incubator-omid}{Apache Software Foundation (ASF)}. Continued supporting the Omid transaction manager project in production. \textit{Omid} presented at Hadoop Summit, 2016, San Jose, CA (USA). \textit{Omid, reloaded: scalable and Highly-Available transaction processing} paper. In USENIX FAST, 2017 \textbf{20 Citations}.
\item \textbf{Scalable Content Ingestion Platform (2015)}: Worked at the multi-tenant content ingestion platform at Search organization. Added High Availability to the Omid Transaction Manager for HBase. Scaled Omid in multi-core architectures. Supported the Omid transaction manager in the production infrastructure of the content ingestion platform. Started exploring the transfer of Omid as open-source project to the Apache Software Foundation.
\end{itemize}
}

\cventry{2012--2015}{\large Research Engineer}{Scalable Computing Group @ Yahoo Labs.}{\textbf{Roles}: Distributed Systems Expert, Research Software Engineer}{Spain}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item \textbf{Omid - Transaction Manager for Big Datastores (2014)}: Re-architected the original codebase and implemented new features. Supported the Omid integration in Sieve project (Yahoo's large scale Internet content ingestion platform). Presented Omid and its poster at Yahoo's internal technical conference (Techpulse Conf. 2014).
\item \textbf{Edentity/Pachiderm - Ubiquitous Content Access and Management (2014)}: Ubiquitous content access and management of personal data (images, video) held on 3rd party services (Flickr, GDrive, Dropbox). Designed and implemented a scalable synchronization data module. Defined and implemented a RESTful API for each module defined (User Registration, Search, Content Fetching).
\item \textbf{RiddlR - Percolator-like Incremental Processing System (2013)}: Prototyped the framework and built a multi-stage example application on top of it. Presented RiddlR and its poster at Yahoo's Techpulse Conf. 2013.
\item \textbf{CumuloNimbo - 7th European Framework Programme (FP7-257993) (2012--2013)}: Designed and implemented a prototype of an incremental processing system for Big Datastores. Added durability guarantees to HBase through BookKeeper. Represented Yahoo in project meetings and evaluation sessions.
\end{itemize}
}

\cventry{2011--2012}{\large Software Architect}{Lumata}{\textbf{Roles}: Distributed Systems Expert, Architect}{Spain}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item \textbf{Giddra Project - SONY Socialife Application (2012)}: High Scalable Big-Data Backend Platform for web and social content ingestion and aggregation. Contributed to the architectural definition of the platform. Did coordination over multiple teams. Defined the REST API for allowing clients to access/use the backend.
\end{itemize}
}

\cventry{2010--2011}{\large Freelance Software Architect/Engineer}{Local Greenhouse Cooperative in Zaragoza}{\textbf{Roles}: Software Architect, Software Engineer}{Spain}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item Analysis, design and Ruby/Rails implementation of a web application to manage the different domains of a greenhouse farm. LoC $\simeq$ 20,000.
\end{itemize}
}

\cventry{2003--2010}{\large Software Architect/Research Engineer}{School of CS at Univ. Politécnica de Madrid (UPM)}{\textbf{Roles}: Distributed Systems Expert, Software Architect, Software Engineer}{Spain}{%
I participated in European and national research projects that included the analysis, design, implementation and testing of different kinds of middleware architectures and applications.
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item \textbf{NEXOF-RA: NESSI Open Framework - Reference Architecture (2008--2010)}: 7th European Framework Programme (FP7-216446). Contributed to a reference architecture (RA) for a European service platform. Built the specification of a set of architectural patterns for non-functional attributes and analysis of how to integrate cloud platforms in the RA.
\item \textbf{Highly Scalable Platform for the Construction of Dependable and Ubiquitous Services (2007--2010)}: Spanish Ministry of Education and Science (TIN2007-67353-C02). Did analysis and tests of consistency problems that arose in end-user applications when second-level caches (e.g. Coherence, JBoss cache) are combined with object persistence mechanisms (e.g. Hibernate).
\item \textbf{AUTOMAN: Autonomic Management of Grid-Based Enterprise Services (2006--2007)}: Did the integration of self-configuration and self-repair properties of autonomic computing in the core of a cloud platform at INRIA (France).
\item \textbf{High Performance Distributed Systems (2006--2009)}: Community of Madrid (S-0505/TIC/000285). Developed a high-available and scalable service for the JOnAS J(2)EE application server. It provided high availability for critical applications deployed in application server clusters, scaling-out the cluster when overloaded. UPM \& BULL signed a pre-agreement to include it in the commercial version. LoC Java (HA\&S Service) $\simeq$ 4,000.
\item \textbf{S4ALL (Services for All) (2005--2007)}: 5th European Framework Programme (IST-2001-37126). Developed a high-available service for the JOnAS application server maintained by Bull SAS (France). Available since v.4.8. LoC Java (JOnAS) $\simeq$ 150,000.
\item \textbf{AUTONOMIC: Autonomic, Dependable and Middleware for Scalable, Distributed, Ubiquitous and Highly Available e-Services (2004--2007)}: Spanish Ministry of Education and Science (TIN2004-07474-C02-01). Built an open-source reference implementation of the WS-CAF specification for adding transactions to SOAP Web Services. LoC $\simeq$ 50,000.
\item \textbf{ADAPT: Middleware for Adaptive and Composable Distributed Components (2002--2005)}: EUREKA/ITEA project (Label 04025). Implemented a transactional-aware replication architecture for stateful EJBs for JBoss. LoC Java $\simeq$ 10,600. Open-sourced the implementation of the Activity Service specification to add advanced transactions models to J2EE. LoC Java $\simeq$ 10,000.
\end{itemize}
}

\cventry{2001--2003}{\large Lecturer}{School of CS at Universidad Pontificia de Salamanca (Madrid Campus)}{\textbf{Roles}: Lecturer}{Spain}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item Courses on Operating Systems and Programming (C and Pascal).
\end{itemize}
}

\cventry{2000--2001}{\large Systems Administrator}{School of CS at Universidad Pontificia de Salamanca (Madrid Campus)}{\textbf{Roles}: Systems Administrator}{Spain}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item Managed and maintained UNIX/Linux servers and Windows workstations: task automation, security.
\end{itemize}
}

\cventry{1999}{\large Quality Analyst}{Meta 4 S.A. (now Cegid)}{\textbf{Roles}: Quality Analyst}{Madrid, Spain}{%
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt,parsep=3pt,partopsep=0pt]
\item Tested the database connection modules of Meta4's ERP suite (now Cegid), gaining hands-on experience with multiple DBMSs, including Oracle, Microsoft SQL Server, Informix, and Sybase, as well as JDBC (Java Database Connectivity). My responsibilities included configuring database connections via JDBC, planning and executing tests, analyzing results, and reporting bugs to ensure system reliability and performance.
\end{itemize}
}

\vspace{-0.2cm}

%---------------------------------- PATENTS --------------------------------------------
\section{Patents}

\cventry{2025 App.}{18/512,871}{Systems and methods for automatically adding text content to generated images}{}{}{}
\cventry{2024 App.}{18/365,941}{Method and system for webpage classification and content delivery}{}{}{}

%---------------------------------- PATENTS ----------------------------------------------------------------------------------------

%------------- PROFESSIONAL EXPERIENCE --------------------------------------------

%------------- ACADEMIC RESEARCH EXPERIENCE --------------------------------------------
\section{Academic Research Experience}

\cventry{2003--2011}{\large Researcher}{School of CS at Universidad Politécnica de Madrid (UPM)}{}{Spain}{
\textit{Detailed achievements}:%
}

\cventry{}{Ph.D. Thesis}{Middleware for High Available and Scalable Multi-Tier and Service-Oriented Architectures}{2003--2009}{Advisors: Prof.~Marta Patiño-Martínez and Prof.~Ricardo Jiménez-Péris (UPM)}{
 \textbf{Specialization:} \textit{Distributed Systems, Transactional Systems, Scalability, High Availability, SOAs}\\
- I developed a brand-new approach to provide high availability and scalability to multi-tier architectures by combining snapshot-isolation and an innovative vertical replication approach.
}

\cventry{}{Research Internship}{SARDES Research Group at INRIA Grenoble (France)}{2007}{Advisor: Prof. Sara Bouchenak}{
- Integration of self-configuration and self-repair properties of autonomic computing in the core of a cloud platform.
}

\cventry{}{Publications in top conferences and journals}{}{}{}{
- \textit{Elastic SI-Cache: Consistent and Scalable Caching in Multi-Tier Architectures}. In VLDB Journal, 2011 \textbf{44 Citations}\newline
- \textit{Scalability Evaluation of the Replication Support of JOnAS, an Industrial J2EE Application Server}. In EDCC Conf., Valencia (Spain), 2010 \textbf{10 Citations}\newline
- \textit{A System of Architectural Patterns for Scalable, Consistent and Highly Available Multi-tier Service Oriented Infrastructure}. In Architecting Dependable Systems VI, Springer, 2009 \textbf{13 Citations}\newline
- \textit{Consistent and Scalable Cache Replication for Multi-tier J2EE Applications}. In ACM/IFIP/USENIX Middleware Conf., CA (USA), 2007 \textbf{43 Citations}\newline
- \textit{WS-Replication: A Framework for Highly Available Web Services}. In ACM WWW Conf., Edinburgh, 2006 \textbf{230 Citations}\newline
- \textit{Highly Available Long Running Transactions and Activities for J2EE Applications}. In IEEE ICDCS Conf., Lisbon (Portugal), 2006 \textbf{28 Citations}\newline
- \textit{ZenFlow: A Visual Tool for Web Service Composition}. In IEEE VL/HCC Conf., Dallas (USA), 2005  \textbf{53 Citations}\newline
}
%------------- ACADEMIC RESEARCH EXPERIENCE --------------------------------------------
\vspace{0.2cm}
%------------- COMPUTER SKILLS --------------------------------------------
\section{Technical Skills}
\cvline{Arch, Design \& Processes}{\small Software Architecture and Design, Design patterns, RESTful APIs, UML, Agile}
\cvline{Lang. \& Fmwk.}{\small Python, PyTorch, TF, Scikit, HuggingFace, LangChain, LangGraph, Autogen, CrewAI, OpenAI Swarm, Java, Rust, Go, Ray, Pandas, Dask, JavaScript (basic), \LaTeX, HTML\ldots{}}
\cvline{Cloud}{\small AWS, GCloud, Docker, Kubernetes}
\cvline{DBMS}{\small Experience with Relational, NoSQL, and Vector DBs}
\cvline{OS Admin.}{\small UNIX/Linux flavors, Android, iOS, Windows}
\cvline{IDEs/Tools}{\small Cursor, Claude Code, Windsurf, VSCode, IntelliJ, Vi, Emacs, UNIX scripts, VCS (Git, Github, GitLab) \& CI/CD (GitHub Actions, GitLab CI)\ldots{}}
%\cvline{Enterprise}{\small  Economy and business management basics}
\vspace{-0.4cm}
%------------- COMPUTER SKILLS --------------------------------------------
\vspace{0.2cm}
%------------- EDUCATION --------------------------------------------
\section{Courses}
\cventry{2025}{Claude Code: A Highly Agentic Coding Assistant}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/8a8a3b69-c549-4f9e-a301-8105436e4ff4?usp=sharing}{Certificate}}{}
\cventry{2025}{Model Context Protocol: Advanced Topics}{Anthropic Education}{}{\href{http://verify.skilljar.com/c/d7e2d2xp2hu9}{Certificate}}{}
\cventry{2025}{Introduction to Model Context Protocol}{Anthropic Education}{}{\href{http://verify.skilljar.com/c/aaofdzhtwit2}{Certificate}}{}
\cventry{2025}{Claude Code in Action}{Anthropic Education}{}{\href{https://verify.skilljar.com/c/kfpzhosaxa35}{Certificate}}{}
\cventry{2025}{Claude with the Anthropic API}{Anthropic Education}{}{\href{https://verify.skilljar.com/c/k3pctnrj4k34}{Certificate}}{}
\cventry{2025}{LLMs as Operating Systems: Agent Memory (Letta)}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/24080236-1809-44a5-af44-31f843eb7168?usp=sharing}{Certificate}}{}
\cventry{2025}{ACP: Agent Communication Protocol}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/da472e4b-b5a2-4d6e-bfbc-78615f32af0d?usp=sharing}{Certificate}}{}
\cventry{2025}{Fundamentals of Agents}{HuggingFace}{}{}{}
\cventry{2025}{Building toward Computer Use with Anthropic}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/e3d34e5d-0865-4e25-8ab5-b1156cff1b82?usp=sharing}{Certificate}}{}
\cventry{2025}{MCP: Build Rich-Context AI Apps with Anthropic}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/e355dfbc-c428-426f-87ae-9473cd837b79?usp=sharing}{Certificate}}{}
\cventry{2025}{Attention in Transforners: Concepts and Code in PyTorch}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/3ed4ede6-132d-4c48-adac-1929a17a8980?usp=sharing}{Certificate}}{}
\cventry{2025}{How Transformer LLMs Work}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/73a5c102-d10f-4981-9c27-058505464db9?usp=sharing}{Certificate}}{}
\cventry{2025}{Practical Multi AI Agents and Advanced Use Cases with crewAI}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/1ff3a3e1-9cc0-43f7-a0e9-7069fe6a5c33?usp=sharing}{Certificate}}{}
\cventry{2024}{Multi AI Agent Systems with CrewAI}{DeepLearning.AI}{}{\href{https://www.linkedin.com/in/fperezsorrosal/overlay/1733693789455/single-media-viewer/}{Certificate}}{}
\cventry{2024}{Knowledge Graphs for RAG}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/e9934e71-56c4-4776-b59a-598d58f64a60?usp=sharing}{Certificate}}{}
\cventry{2024}{AI Agentic Design Patterns with AutoGen}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/f5763004-1e46-4153-a466-9fede55d2c8c?usp=sharing}{Certificate}}{}
\cventry{2024}{Functions, Tools and Agents with LangChain}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/2b4a25d6-3d3c-43b4-9909-29a5594d71a4?usp=sharing}{Certificate}}{}
\cventry{2024}{Improving Accuracy of LLM Applications}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/9ba0d65d-0c9b-4939-b5b9-7e5ac0369167?usp=sharing}{Certificate}}{}
\cventry{2024}{LangChain for LLM Application Development}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/f7c4a5b8-4bb9-4363-bf2e-14e475537873?usp=sharing}{Certificate}}{}
\cventry{2024}{AI Agents in LangGraph}{DeepLearning.AI}{}{\href{https://learn.deeplearning.ai/accomplishments/34f2e69e-04f8-49b9-b402-2cc7331122d5?usp=sharing}{Certificate}}{}
\cventry{2024}{RAG Developer Bootcamp}{Pinecone + Anyscale}{In-Person}{San Francisco}{\href{https://www.anyscale.com/events/2024/03/08/rag-developer-bootcamp}{Bootcamp}}
\cventry{2023}{LLM102x: Large Language Models: Foundation Models from the Ground Up}{edX/Databricks}{}{\href{https://courses.edx.org/certificates/e36174eec12748e7b62afd517060cf2d}{Certificate}}{}
\cventry{2023}{LLM101x: Large Language Models: Application through Production}{edX/Databricks}{}{\href{https://courses.edx.org/certificates/efcc7ec7b2234b538809447c1f37babf}{Certificate}}{}
\cventry{2023}{LLM Bootcamp}{FSDL}{In-Person}{South San Francisco, CA (USA)}{}
\cventry{2023}{Yahoo Leadership Program}{}{The Forem}{Remote}{}
\cventry{2022}{Full Stack Deep Learning 22'Edition}{FSDL}{}{\href{https://fullstackdeeplearning.com/course/2022/}{Course}}{}
\cventry{2022}{Machine Learning Specialization (3 Courses)}{Coursera/DeepLearning.AI/Stanford}{}{\href{https://www.coursera.org/account/accomplishments/specialization/certificate/KREGWAZ87SQN}{Certificate}}{}
\cventry{2021}{Full Stack Deep Learning 21'Edition}{FSDL}{}{\href{https://fullstackdeeplearning.com/spring2021/}{Course}}{}
\cventry{2019}{Machine Learning Specialization (4 Courses)}{Coursera/Univ. Washington}{}{\href{https://www.coursera.org/account/accomplishments/specialization/certificate/UY6W586XQMW3}{Certificate}}{}
\cventry{2018}{Mathematics for Machine Learning Specialization (3 Courses)}{Coursera/Imperial College London}{}{\href{https://www.coursera.org/account/accomplishments/specialization/K7TBGLD4Y6ML}{Certificate}}{}
\cventry{2018}{Deep Learning Specialization (5 Courses)}{Coursera/DeepLearning.AI}{}{\href{https://www.coursera.org/account/accomplishments/specialization/YTPXQJ42EUCK}{Certificate}}{}
\cventry{2011}{Certificate of Training, Advanced Scala}{Typesafe}{Switzerland}{}{}
\cventry{2011}{Certificate of Training, Scala}{Typesafe}{Switzerland}{}{}
\cventry{2011}{Course in Business Administration and Economics (268 hours)}{Funded by Community of Madrid}{Spain}{}{}
\vspace{-0.2cm}

\section{Education}
\cventry{2003-2009}{Ph.D. in CS}{School of CS at Universidad Politécnica de Madrid (UPM)}{Spain}{}{}
\cventry{2004}{Postgraduate Certificate in Education}{Educational Sciences Institute at Universidad Complutense de Madrid (UCM)}{Spain}{}{}
\cventry{1994--2001}{B.Eng \& M.Sc. in CS}{School of CS at Universidad Pontificia de Salamanca (Madrid Campus)}{Spain}{}{}
%\cventry{year--year}{Degree}{Institution}{City}{\textit{Grade}}{Description}  % arguments 3 to 6 can be left empty
%\cventry{year--year}{Degree}{Institution}{City}{\textit{Grade}}{Description}
\vspace{-0.4cm}
%------------- EDUCATION --------------------------------------------
\vspace{0.2cm}
%------------- COMMUNICATION SKILLS --------------------------------------------
\section{Communication Skills}
%\vspace{-0cm}
\cvline{}{\small Presented research findings at both international and national conferences, 
effectively communicating complex ideas to diverse audiences. Delivered project updates in internal meetings within corporate environments. Additionally, I demonstrated teaching and mentoring skills by conducting undergraduate and Ph.D.-level courses at the university, fostering 
understanding and engagement among students. }
\vspace{-0.2cm}
%------------- COMMUNICATION SKILLS --------------------------------------------
\vspace{0.2cm}
%------------- LANGUAGES --------------------------------------------
\section{Languages}
%\vspace{-0cm}
\cvcomputer{Spanish}{\small \textit{Mother tongue}}{English}{\small \textit{Fluent}} % (written and spoken)
\cvcomputer{French}{\small \textit{Intermediate proficiency}}{Catalan}{\small \textit{Intermediate proficiency}} % (listening, reading, \& speaking)
\vspace{-0.4cm}
%------------- LANGUAGES --------------------------------------------
\vspace{0.2cm}
%------------- OTHER ACTIVITIES RELATED TO CS --------------------------------------------
\section{Other Activities Related to Computer Science}
\cventry{}{Open Source Project Maintainer}{}{}{}{
- \textit{mdbook-bib}: Rust-based bibliography management plugin for mdBook (official Rust documentation system). Active maintenance and community engagement with significant adoption.\href{Crates Info}{https://crates.io/crates/mdbook-bib}
}
\cventry{}{Committer in the Apache Software Foundation}{}{}{}{
- \textit{Apache Omid project, a high-performant and scalable Transaction Manager for HBase}
}
\cventry{}{Reviewer in International Academic Conferences}{}{}{}{
- \textit{IEEE International Symposium on Reliable Distributed Systems (SRDS)}, 2008 and 2009\newline
- \textit{IEEE International conference in Distributed Computing Systems (ICDCS)}, 2009\newline
- \textit{International Conference on Parallel and Distributed Computing (Europar)}, 2007 and 2010\newline
- \textit{ACM Symposium on Applied Computing (SAC)}, 2008 and 2010\newline
- \textit{International Conference on Service-Oriented Computing (ICSOC)}, 2009\newline
- \textit{EDBTs International Workshop on Data Management in Peer-to-peer Systems (DAMAP)}, 2009\newline
- \textit{International Workshop on Assurance in Distributed Systems and Networks (ADSN)}, 2010
}
\cventry{}{Speaker/Attendee in Academic/Technical Conferences}{}{}{}{
- \textit{Agentic AI Summit}, Aug 2nd, 2025, Berkeley, CA (USA)\newline
- \textit{AI Engineer World's Fair}, Jun 3rd-5th, 2025, San Francisco, CA (USA)\newline
- \textit{MLSys 2025 conference}, May 11th-15th, 2025, Santa Clara, CA (USA)\newline    
- \textit{Neurips 2024 conference}, Dec 10th-15th, 2024, Vancouver, BC (Canada)\newline
- \textit{ICML 2024 conference}, Jul 21st-27th, 2024, Vienna (Austria)\newline
- \textit{AI Engineer World's Fair}, Jun 25th-27th, 2024, San Francisco, CA (USA)\newline
- \textit{MLSys 2024 conference}, May 13th-16th, 2024, Santa Clara, CA (USA)\newline
- \textit{W\&B Fully Connected Conference 2024, The Era of Generative AI}, Apr 17th-18th, 2024, San Francisco, CA (USA)\newline
- \textit{Neurips 2023 conference}, Dec 10th, 2023, New Orleans, LA (USA)\newline
- \textit{Amazon Re:Invent 2023}, Nov 27th-30th, 2023, Las Vegas, NV (USA)\newline
- \textit{Ray Summit 2023}, Sep 18th-20th, 2023, San Francisco, CA (USA)\newline
- \textit{ICML 2023 conference}, Jul 23rd-29th, 2023, Honolulu, Hawaii (USA)\newline
- \textit{MLSys 2023 conference}, Jun 4th-8th, 2023, Miami, FL (USA)\newline
- \textit{Ray Summit 2022}, Aug 23rd-24th, 2022, San Francisco, CA (USA)\newline
- \textit{MLSys 2022 conference}, Aug 31st-Sept 3rd, 2022, Santa Clara, CA (USA)\newline
- \textit{ACL 2019 conference (Speaker)}, Jul 28th-Aug 2nd, 2019, Florence (Italy)\newline
- \textit{@Scale conference}, Aug 31st, 2016, San Jose, CA (USA)\newline
- \textit{Hadoop Summit (Speaker)}, Jun 28th-30th, 2016, San Jose, CA (USA)\newline
- \textit{@Scale conference}, Sep 14th, 2015, San Jose, CA (USA)\newline
- \textit{Hadoop Summit Europe}, Apr 15th-16th, 2015, Brussels (Belgium)\newline
- \textit{Hadoop Summit Europe}, Apr 2nd-3rd, 2014, Amsterdam (Netherlands)\newline
- \textit{NoSQL Matters Conf.}, Nov 21st-22nd, 2014, Barcelona (Spain)\newline
- \textit{NoSQL Matters Conf.}, Nov 29th-30th, 2013, Barcelona (Spain)\newline
- \textit{NoSQL Matters Conf.}, Oct 6th, 2012, Barcelona (Spain)\newline
- \textit{IEEE International Symposium on Reliable Distributed Systems (SRDS)}, Oct 4th-7th, 2011, Madrid (Spain)\newline
- \textit{World Wide Web Conference}, Apr 20th-24th, 2009, Madrid (Spain)\newline
- \textit{Spanish Conference on Concurrency and Distributed Systems}, Sep 13th-16th, 2005, Granada (Spain)\newline
- \textit{ObjectWebCon'05}, Jan 17th-20th, 2005, Lyon (France)\newline
- \textit{ObjectWeb's Workshop on Transactions}, Feb 23rd-24th, 2004, Grenoble (France)\newline
- \textit{ObjectWeb's Architecture Meeting}, Jan 13th-15th, 2004, Sevilla (Spain)
}
\cventry{}{Member}{}{}{}{
- \textit{Apache Software Foundation (ASF)}, https://www.apache.org/\newline
- \textit{ObjectWeb Consortium}, http://www.ow2.org\newline
- \textit{Java Community Process program (JCP)}, http://jcp.org
}
%------------- OTHER ACTIVITIES RELATED TO CS --------------------------------------------
\vspace{0.2cm}
%------------- HOBBIES AND INTERESTS --------------------------------------------
\section{Hobbies and Interests}
\cvline{}{\small Beyond my core professional focus, but some way related to it, I have a strong interest in the 
intersection of fields such as neuroscience, psychology, decision-making, cognitive sciences, learning techniques, 
behavioral economics, and philosophy, as they offer valuable insights into human behavior, intelligence, and how 
the brain works (and why!) I am deeply fascinated by the mechanisms of human thought, learning, and behavior, and
how these insights can inform and inspire advancements in AI and our daily lives and wellbeing in general.
}
\cvline{}{\small In my personal life, I enjoy staying active through activities like running, mountain biking, yoga, cold-plunging, 
and playing tennis, which not only keep me physically fit but also provide a sense of balance and focus.
}
%------------- HOBBIES AND INTERESTS --------------------------------------------

%------------- PERSONAL INFO --------------------------------------------
%\section{Personal Information}
%\cvcomputer{Nationality}{\small \textbf{Spanish}}{Passport}{\small \textbf{XXXXXXX}}
%\cvcomputer{Place of birth}{\textbf{XXXX, XXXX}}{Driving license}{\small \textbf{XXXXXX}}
%\cvcomputer{Date of birth}{\small \textbf{XX\textsuperscript{th} XXXX XXXX}}{}{\small \textbf{}}
%------------- PERSONAL INFO --------------------------------------------

%\section{Interests}
%\cvline{hobby 1}{\small Description}
%\cvline{hobby 2}{\small Description}
%\cvline{hobby 3}{\small Description}

%\section{Computer skills}
%\cvcomputer{category 1}{XXX, YYY, ZZZ}{category 4}{XXX, YYY, ZZZ}
%\cvcomputer{category 2}{XXX, YYY, ZZZ}{category 5}{XXX, YYY, ZZZ}
%\cvcomputer{category 3}{XXX, YYY, ZZZ}{category 6}{XXX, YYY, ZZZ}


%\section{Extra 1}
%\cvlistitem{Item 1}
%\cvlistitem{Item 2}
%\cvlistitem[+]{Item 3}            % optional other symbol
%
%\renewcommand{\listitemsymbol}{-} % change the symbol for lists
%
%\section{Extra 2}
%\cvlistdoubleitem{Item 1}{Item 4}
%\cvlistdoubleitem{Item 2}{Item 5 \cite{book1}}
%\cvlistdoubleitem{Item 3}{}
%
%
%\section{Experience}
%\subsection{Vocational}
%
%\cventry{year--year}{Job title}{Employer}{City}{}{General description no longer than 1--2 lines.\newline{}%
%Detailed achievements:%
%\begin{itemize}%
%\item Achievement 1;
%\item Achievement 2, with sub-achievements:
%  \begin{itemize}%
%  \item Sub-achievement (a);
%  \item Sub-achievement (b), with sub-sub-achievements (don't do this!);
%    \begin{itemize}
%    \item Sub-sub-achievement i;
%    \item Sub-sub-achievement ii;
%    \item Sub-sub-achievement iii;
%    \end{itemize}
%  \item Sub-achievement (c);
%  \end{itemize}
%\item Achievement 3.
%\end{itemize}}
%\cventry{year--year}{Job title}{Employer}{City}{}{Description line 1\newline{}Description line 2}
%\subsection{Miscellaneous}
%\cventry{year--year}{Job title}{Employer}{City}{}{Description}


% Publications from a BibTeX file without multibib\renewcommand*{\bibliographyitemlabel}{\@biblabel{\arabic{enumiv}}}% for BibTeX numerical labels
\nocite{*}
\bibliographystyle{plain}
%\bibliography{publications}       % 'publications' is the name of a BibTeX file

% Publications from a BibTeX file using the multibib package
%\section{Publications}
%\nocitebook{book1,book2}
%\bibliographystylebook{plain}
%\bibliographybook{publications}   % 'publications' is the name of a BibTeX file
%\nocitemisc{misc1,misc2,misc3}
%\bibliographystylemisc{plain}
%\bibliographymisc{publications}   % 'publications' is the name of a BibTeX file

\end{document}


%% end of file `template_en.tex'.
